{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punc = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop2 = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "[stop.append(x) for x in ['nothing','column','middle','passed','need','lots','many','avenue','take',\n",
    "                          'area','top','go','else','consider','high','visiting','the','much','would','guess']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.csv',encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews['title'] = (reviews['title']\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(lambda x: ' '.join([j for j in x.split() if j not in stop ])) ## Quitar stopwords\n",
    "                    .str.replace('(?:\\'|\\.|[\\¿\\?\\!\\¡0-9,;]*)','') # quitar numeros signos de exclamación etcetera\n",
    "                    .map(lambda x: ' '.join([j for j in x.split() if j not in set(punc)] )) # remover carácteres especiales\n",
    "                    .str.normalize('NFKD').str.encode('ascii',errors='ignore').str.decode('utf-8') # Sustituir acentos\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews['comment'] = (reviews['comment']\n",
    "                      .str.strip() # Borrar espacios vacíos al primcipio y al final\n",
    "                      .str.lower()\n",
    "                      .map(lambda x: ' '.join([j for j in x.split() if j not in stop])) ## Quitar stopwords\n",
    "                      .str.replace('(?:\\'|\\.|[\\¿\\?\\!\\¡0-9,;]*)','') # quitar numeros signos de exclamación etcetera\n",
    "                      .map(lambda x: ' '.join([j for j in x.split() if j not in set(punc)] )) # remover carácteres especiales\n",
    "                      .str.normalize('NFKD').str.encode('ascii',errors='ignore').str.decode('utf-8') # Sustituir acentos\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = (reviews\n",
    "           .drop('Unnamed: 0',axis=1)\n",
    "           .assign(sentiment = lambda df: df['rating'].map( lambda x: 1 if x>30 else 0 ))\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test = train_test_split(reviews['comment'],reviews['sentiment'],random_state=0)\n",
    "X_train,X_test,y_train,y_test = reviews['comment'],reviews['comment'],reviews['sentiment'],reviews['sentiment']\n",
    "X_vec = CountVectorizer(ngram_range=(1,2)).fit(X_train)\n",
    "# X_vec = TfidfVectorizer(ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vec = X_vec.transform(X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec,y_train)\n",
    "feature_names = np.array(X_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest coefs: \n",
      "['traffic' 'big' 'interesting' 'busy' 'stops' 'climb' 'crowded' 'market'\n",
      " 'buses' 'able']\n",
      "\n",
      "largest coefs: \n",
      "['beautiful' 'great' 'history' 'city' 'sunday' 'walk' 'monuments' 'amazing'\n",
      " 'mexican' 'wonderful']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coefs = model.coef_[0].argsort()\n",
    "print('smallest coefs: \\n{}\\n'.format(feature_names[coefs][:10]))\n",
    "print('largest coefs: \\n{}\\n'.format(feature_names[coefs][:-11:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scastaneda01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim-3.4.0-py3.6-win-amd64.egg\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_clean = [doc.split() for doc in X_train]\n",
    "dictionary=0\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código debajo tarda bastante tiempo en correr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Lda = gensim.models.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word=dictionary,passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del Topic Modelling no son lo que esperabamos pues no hay tópicos muy evidentes que podamos obtener a partir de las palabras.\n",
    "\n",
    "¿Cuál creen que haya sido el problema?  \n",
    "*Noten que muchas de las palabras que aparecen en el tópico 1 están en español.*\n",
    "\n",
    "¿Cuál creen que sería una solución ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.023*\"de\" + 0.021*\"angel\" + 0.020*\"reforma\" + 0.020*\"la\" + 0.019*\"mexico\" + 0.018*\"city\" + 0.015*\"paseo\" + 0.014*\"beautiful\" + 0.013*\"walk\" + 0.012*\"one\"')\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3,num_words=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '0.016*\"walk\" + 0.014*\"people\" + 0.014*\"great\" + 0.013*\"place\" + 0.012*\"street\" + 0.011*\"reforma\" + 0.011*\"sunday\" + 0.010*\"see\" + 0.010*\"walking\" + 0.010*\"nice\"')\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3,num_words=10)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, '0.036*\"city\" + 0.027*\"mexico\" + 0.015*\"reforma\" + 0.012*\"beautiful\" + 0.011*\"walk\" + 0.009*\"nice\" + 0.008*\"see\" + 0.008*\"street\" + 0.007*\"paseo\" + 0.007*\"chapultepec\"')\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3,num_words=10)[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
